import asyncio
import sys
import re

# æ™ºæ…§ä¾è³´æª¢æŸ¥
def check_dependencies():
    """æª¢æŸ¥ä¸¦è‡ªå‹•å®‰è£ç¼ºå¤±çš„ä¾è³´"""
    missing_deps = []
    
    try:
        from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
    except ImportError:
        missing_deps.append("playwright")
    
    if missing_deps:
        print("âŒ æª¢æ¸¬åˆ°ç¼ºå¤±çš„ä¾è³´å¥—ä»¶:")
        for dep in missing_deps:
            print(f"   - {dep}")
        
        print("\nğŸš€ è«‹åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤å®‰è£ä¾è³´:")
        print("   python setup.py")
        print("   æˆ–æ‰‹å‹•å®‰è£:")
        print("   pip install -r requirements.txt")
        print("   playwright install chromium")
        
        response = input("\næ˜¯å¦ç¾åœ¨è‡ªå‹•å®‰è£? (y/N): ").lower().strip()
        if response in ['y', 'yes', 'æ˜¯']:
            import subprocess
            try:
                print("ğŸ“¦ æ­£åœ¨å®‰è£ä¾è³´...")
                subprocess.run([sys.executable, "setup.py"], check=True)
                print("âœ… ä¾è³´å®‰è£å®Œæˆï¼Œè«‹é‡æ–°é‹è¡Œç¨‹å¼")
            except subprocess.CalledProcessError:
                print("âŒ è‡ªå‹•å®‰è£å¤±æ•—ï¼Œè«‹æ‰‹å‹•åŸ·è¡Œ python setup.py")
            except FileNotFoundError:
                print("âŒ æœªæ‰¾åˆ° setup.pyï¼Œè«‹æ‰‹å‹•å®‰è£ä¾è³´")
        
        sys.exit(1)

# åŸ·è¡Œä¾è³´æª¢æŸ¥
check_dependencies()

# ç¾åœ¨å¯ä»¥å®‰å…¨å°å…¥
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

async def extract_caption_from_meta(page) -> str:
    """
    å¾ meta æ¨™ç±¤ä¸­æå–æ–‡æ¡ˆ - å„ªåŒ–ç‰ˆæœ¬
    """
    try:
        # å˜—è©¦å¾ og:description meta æ¨™ç±¤ç²å–
        og_description = await page.get_attribute('meta[property="og:description"]', 'content')
        if og_description and len(og_description) > 50:
            print(f"å¾ og:description æŠ“å–åˆ°æ–‡æ¡ˆ (é•·åº¦: {len(og_description)})")
            # æ¸…ç†æ ¼å¼ï¼Œæå–å¼•è™Ÿå…§çš„å…§å®¹
            # åŒ¹é…æ¨¡å¼ï¼šç”¨æˆ¶å æ–¼ æ—¥æœŸ : "æ–‡æ¡ˆå…§å®¹"
            match = re.search(r':\s*"([^"]+)"', og_description)
            if match:
                return match.group(1).strip()
            # å¦‚æœæ²’æœ‰å¼•è™Ÿæ ¼å¼ï¼Œå˜—è©¦å…¶ä»–æ¸…ç†æ–¹å¼
            cleaned = re.sub(r'^[^:]+:\s*', '', og_description)
            return cleaned.strip()
        
        # å˜—è©¦å¾ description meta æ¨™ç±¤ç²å–
        description = await page.get_attribute('meta[name="description"]', 'content')
        if description and len(description) > 50:
            print(f"å¾ description æŠ“å–åˆ°æ–‡æ¡ˆ (é•·åº¦: {len(description)})")
            # æ¸…ç†æ ¼å¼ï¼Œæå–å¼•è™Ÿå…§çš„å…§å®¹
            match = re.search(r':\s*"([^"]+)"', description)
            if match:
                return match.group(1).strip()
            # å¦‚æœæ²’æœ‰å¼•è™Ÿæ ¼å¼ï¼Œå˜—è©¦å…¶ä»–æ¸…ç†æ–¹å¼
            cleaned = re.sub(r'^[^:]+:\s*', '', description)
            return cleaned.strip()
            
    except Exception as e:
        print(f"Meta æ¨™ç±¤æŠ“å–å¤±æ•—: {e}")
    
    return ""

async def get_post_caption(url: str) -> str:
    """
    æŠ“å–Instagramè²¼æ–‡æˆ–Reelsçš„æ–‡æ¡ˆï¼Œå°ˆæ³¨æ–¼å³å´æ–‡å­—å…§å®¹
    """
    print("Launching browser in incognito mode...")
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()
        try:
            print(f"Navigating to {url}...")
            await page.goto(url, wait_until="domcontentloaded", timeout=60000)
            await page.wait_for_timeout(3000)

            print("Attempting to close any popups by pressing Escape key...")
            await page.keyboard.press('Escape')
            print("Escape key pressed. Waiting for UI to settle...")
            await page.wait_for_timeout(2000)

            # --- å„ªåŒ–çš„æŠ“å–ç­–ç•¥ ---
            caption = ""
            
            # ç­–ç•¥ 1: å„ªå…ˆå¾é é¢å…ƒç´ æŠ“å–æ–‡æ¡ˆ (ä¸éœ€è¦é»æ“Šæ›´å¤šæŒ‰éˆ•)
            try:
                print("å˜—è©¦å¾é é¢å…ƒç´ æŠ“å–æ–‡æ¡ˆ...")
                
                # å„ªåŒ–çš„æ–‡æ¡ˆé¸æ“‡å™¨ï¼Œé‡å°Instagramå³å´æ–‡æ¡ˆå€åŸŸ
                caption_selectors = [
                    # Instagram æ–‡æ¡ˆå€åŸŸçš„å¸¸è¦‹é¸æ“‡å™¨
                    'article div[data-testid="post-shared-text"] span',
                    'article span[dir="auto"]',
                    'div[data-testid="post-shared-text"]',
                    'meta + div span[dir="auto"]',
                    # é€šç”¨çš„æ–‡æ¡ˆé¸æ“‡å™¨
                    'h1',
                    'span._ap3a._aaco._aacu._aacx._aada',
                    'span[dir="auto"]',
                    # é‡å°æ–°ç‰ˆInstagramä»‹é¢
                    'div[role="button"] span',
                    'article div span'
                ]
                
                for selector in caption_selectors:
                    try:
                        print(f"å˜—è©¦é¸æ“‡å™¨: {selector}")
                        elements = page.locator(selector)
                        count = await elements.count()
                        print(f"æ‰¾åˆ° {count} å€‹å…ƒç´ ")
                        
                        if count > 0:
                            # å˜—è©¦ç²å–æœ€æœ‰æ„ç¾©çš„æ–‡å­—å…§å®¹
                            for i in range(count):
                                try:
                                    text = await elements.nth(i).inner_text()
                                    text = text.strip()
                                    
                                    # éæ¿¾æ‰æ˜é¡¯çš„éŒ¯èª¤è¨Šæ¯å’ŒçŸ­æ–‡å­—
                                    if (len(text) > 20 and 
                                        "å¾ˆæŠ±æ­‰" not in text and 
                                        "æ’­æ”¾æ­¤å½±ç‰‡æ™‚ç™¼ç”Ÿå•é¡Œ" not in text and
                                        "Instagram" not in text and
                                        "ç™»å…¥" not in text):
                                        
                                        # é¸æ“‡æœ€é•·ä¸”æœ‰æ„ç¾©çš„æ–‡å­—
                                        if len(text) > len(caption):
                                            caption = text
                                            print(f"æ‰¾åˆ°æ›´å¥½çš„æ–‡æ¡ˆ (é•·åº¦: {len(text)}): {text[:100]}...")
                                except Exception as e:
                                    continue
                                    
                    except Exception as e:
                        print(f"é¸æ“‡å™¨ {selector} å¤±æ•—: {e}")
                        continue
                
            except Exception as e:
                print(f"é é¢å…ƒç´ æŠ“å–å¤±æ•—: {e}")
            
            # ç­–ç•¥ 2: å¦‚æœé é¢æŠ“å–å¤±æ•—æˆ–æŠ“åˆ°çš„å…§å®¹å¤ªçŸ­ï¼Œå¾ meta æ¨™ç±¤æŠ“å–
            if not caption or len(caption) < 30:
                print("é é¢å…ƒç´ æŠ“å–çµæœä¸ç†æƒ³ï¼Œå˜—è©¦å¾ meta æ¨™ç±¤æŠ“å–...")
                meta_caption = await extract_caption_from_meta(page)
                if meta_caption and len(meta_caption) > len(caption):
                    caption = meta_caption
                    print(f"å¾ meta æ¨™ç±¤æˆåŠŸæŠ“å–æ–‡æ¡ˆ (é•·åº¦: {len(caption)})")
            
            if caption and len(caption) > 10:
                return caption
            else:
                # æœ€å¾Œçš„ debug è™•ç†
                print("æ‰€æœ‰ç­–ç•¥éƒ½å¤±æ•—ï¼Œä¿å­˜ debug æª”æ¡ˆ...")
                await page.screenshot(path="debug_screenshot.png")
                with open("debug_page.html", "w", encoding="utf-8") as f:
                    f.write(await page.content())
                print("Debug æª”æ¡ˆå·²ä¿å­˜")
                return "ERROR: ç„¡æ³•æ‰¾åˆ°æ–‡æ¡ˆå…§å®¹ã€‚è«‹æª¢æŸ¥ debug æª”æ¡ˆã€‚"

        except PlaywrightTimeoutError:
            print("ERROR: é é¢è¼‰å…¥æˆ–è™•ç†è¶…æ™‚")
            await page.screenshot(path="debug_screenshot.png")
            with open("debug_page.html", "w", encoding="utf-8") as f:
                f.write(await page.content())
            return "ERROR: é é¢è™•ç†è¶…æ™‚ã€‚è«‹æª¢æŸ¥ debug æª”æ¡ˆã€‚"
        except Exception as e:
            print(f"ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
            return f"ERROR: ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}"
        finally:
            print("Closing browser...")
            await context.close()
            await browser.close()
            print("Browser closed.")

async def main():
    """
    Main function to run the scraper.
    Takes the Instagram URL as a command-line argument.
    """
    if len(sys.argv) < 2:
        print("--- Instagram æ–‡æ¡ˆæŠ“å–å™¨ ---")
        print("ä½¿ç”¨æ–¹æ³•: python main.py <instagram_post_url>")
        print("ç¯„ä¾‹: python main.py https://www.instagram.com/p/C2x5J8zR9A9/")
        print("     python main.py https://www.instagram.com/reel/DLbk7VgOwPV/")
        print("\nğŸ’¡ æç¤º: å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œè«‹å…ˆåŸ·è¡Œ python setup.py å®‰è£ä¾è³´")
        return

    post_url = sys.argv[1]

    if "instagram.com/" not in post_url:
        print("éŒ¯èª¤: è«‹æä¾›æœ‰æ•ˆçš„ Instagram URLã€‚")
        return

    print(f"é–‹å§‹æŠ“å–: {post_url}")
    caption_text = await get_post_caption(post_url)

    print("\n" + "="*50)
    print("æŠ“å–åˆ°çš„æ–‡æ¡ˆ:")
    print("="*50)
    print(caption_text)
    print("="*50 + "\n")

if __name__ == "__main__":
    asyncio.run(main())